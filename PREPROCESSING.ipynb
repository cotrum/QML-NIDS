{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b877b7d",
   "metadata": {},
   "source": [
    "# Cleaning Dataset and Obtaining Samples for Testing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca903db",
   "metadata": {},
   "source": [
    "## a preprocessing guide for raw NIDS data for use in QML testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f281ebcc",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ba2057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e7c1a",
   "metadata": {},
   "source": [
    "### Load chosen datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb1eb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask is better for reading large CSVs\n",
    "attack = dd.read_csv(\n",
    "    \"BCCC-CIC-CSE-IDS2018/Tuesday_20_02_2018/tuesday_20_02_2018_loic_http/tuesday_20_02_2018_loic_http.csv\", \n",
    "    low_memory=False, \n",
    "    dtype={'delta_start': 'object',\n",
    "       'handshake_duration': 'object'}\n",
    ")\n",
    "benign = dd.read_csv(\n",
    "    \"BCCC-CIC-CSE-IDS2018/Tuesday_20_02_2018/tuesday_20_02_2018_benign/tuesday_20_02_2018_benign.csv\", \n",
    "    low_memory=False,\n",
    "    dtype={'delta_start': 'object',\n",
    "       'handshake_duration': 'object'}\n",
    ")\n",
    "\n",
    "# randomly sample 500 pts each\n",
    "attack = attack.sample(frac=1, random_state=42).head(500)\n",
    "benign = benign.sample(frac=1, random_state=42).head(500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c35f2",
   "metadata": {},
   "source": [
    "## DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b4f410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintain only numeric columns for now\n",
    "attack = attack.select_dtypes(include=[np.number])\n",
    "benign = benign.select_dtypes(include=[np.number])\n",
    "\n",
    "# Replace inf with NaN (to drop later)\n",
    "attack.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "benign.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Drop columns with >20% missing in attack\n",
    "cols = attack.isnull().mean() < 0.2\n",
    "attack = attack.loc[:, cols]\n",
    "benign = benign.loc[:, cols]\n",
    "\n",
    "# Drop single-value columns (attack)\n",
    "multi_cols = attack.nunique()[attack.nunique() > 1].index\n",
    "shared_cols = [col for col in multi_cols if col in benign.columns]\n",
    "attack = attack[shared_cols]\n",
    "benign = benign[shared_cols]\n",
    "\n",
    "# Drop highly collinear columns (corr > 0.95)\n",
    "corr = attack.corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "to_drop = [col for col in upper.columns if any(upper[col] > 0.95)]\n",
    "attack = attack.drop(columns=to_drop)\n",
    "benign = benign.drop(columns=to_drop)\n",
    "\n",
    "# Drop any column that still has NaNs \n",
    "no_nan_cols = benign.columns[~benign.isnull().any()]\n",
    "attack = attack[no_nan_cols]\n",
    "benign = benign[no_nan_cols]\n",
    "\n",
    "# Remove all 0 rows\n",
    "benign = benign.loc[~(benign == 0.0).all(axis=1)]\n",
    "attack = attack.loc[~(attack == 0.0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea65deb6",
   "metadata": {},
   "source": [
    "## Get importances from GBF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b0b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subflow_fwd_packets', 'packets_count', 'packets_IAT_median', 'max_fwd_packets_delta_len', 'duration', 'bwd_packets_IAT_median', 'packet_IAT_min', 'bwd_packets_IAT_min']\n"
     ]
    }
   ],
   "source": [
    "# 1. Combine and label\n",
    "X = pd.concat([benign, attack], axis=0)\n",
    "y = np.array([0] * len(benign) + [1] * len(attack))  # 0 = benign, 1 = attack\n",
    "\n",
    "# 2. Train an XGBoost classifier\n",
    "model = xgb.XGBClassifier(\n",
    "    eval_metric='logloss', \n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# 3. Pick top 8 most relevant features\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "top_features = importances.nlargest(8).index.tolist()\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51885010",
   "metadata": {},
   "source": [
    "## Construct new cleaned dataset for testing using selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "453f7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant features\n",
    "attack = attack[top_features]\n",
    "benign = benign[top_features]\n",
    "\n",
    "# Save as numpy arrays\n",
    "np.save('500-loic-attack.npy', attack.to_numpy())\n",
    "np.save('500-loic-benign.npy', benign.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
